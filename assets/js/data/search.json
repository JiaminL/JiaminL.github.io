[ { "title": "BERT 实验记录", "url": "/posts/2022/04/Bert-Report/", "categories": "Laboratory, Deep Learning", "tags": "Deep Learning, BERT", "date": "2022-04-27 00:00:00 +0800", "snippet": "实验环境 GPU：GeForce RTX 2080 Ti $\\times 1$ Docker image：tensorflow/tensorflow:1.11.0-gpu CUDA version：9.0 Linux 发行版本：Ubuntu 16.04.5 LTS Python version：2.7.12 实验代码实验所用代码仓库：https://github.com/google-research/bert，其所提供的代码只支持 CoLA、MRPC、MNLI、XNLI 分类任务与 SQuAD、SQuAD 2.0 问答任务。本次实验只对 CoLA 任务进行了测试。所用实验代码为：run_classifier.py。获取时间性能数据该代码中是用 tf.contrib.tpu.TPUEstimator 对象的 train 方法来进行训练，由于我对 TensorFlow 的使用并不熟悉，除了将整个代码改写，我并不知道还有什么方法能够获取到每个 epoch 开始/结束的时间点。但幸运的是，在其输出的一堆 Log 中，我发现了这样的信息：....INFO:tensorflow:global_step/sec: 55.2661INFO:tensorflow:examples/sec: 1768.51INFO:tensorflow:global_step/sec: 94.3678INFO:tensorflow:examples/sec: 3019.77INFO:tensorflow:global_step/sec: 90.2155....程序给出了每秒钟处理的样例数，这意味着，我可以获取训练过程中输出的 examples/sec 然后取平均，从而估计出平均样例处理速度，然后用训练样例的总数 num_examples 去除以平均样例处理速度，从而估计出微调训练时每 epoch 所需的时间，即：time_per_epoch = num_examples / average(examples_per_sec_list)获取GPU占用情况由于我并不知道如何结合 TensorFlow 在代码 run_classifier.py 中监控 GPU 占用情况，所以我使用了 watch -n 0.2 &quot;nvidia-smi | grep % &amp;gt;&amp;gt; $NVIDIA_OUT_FILE 命令来每 0.2s 运行一次 nvidia-smi 命令，并用 grep % 过滤输出只留下 GPU 占用情况相关的行，并输出到 $NVIDIA_OUT_FILE 文件。 实际执行过程中，nvidia-smi | grep % &amp;gt;&amp;gt; $NVIDIA_OUT_FILE 命令并非严格 0.2s 执行一次，可用如下命令验证： $ watch -n 0.2 &quot;date +%S.%N &amp;gt;&amp;gt; tmp.txt; sleep 0.1&quot;$ cat tmp.txt55.13831856355.44750274055.75752840256.068227311 可以看出命令 date +%S.%N &amp;gt;&amp;gt; tmp.txt; sleep 0.1 并非每 0.2s 启动一次，而是等该命令执行完以后，停顿 0.2s 后再次启动，因此该命令会大约 0.31s 执行一次为了矫正时间误差，我改进为用如下命令来监控 GPU 使用情况：$ watch -n 0.2 &quot;nvidia-smi | grep % &amp;gt;&amp;gt; $NVIDIA_OUT_FILE; date +%s.%N &amp;gt;&amp;gt; $NVIDIA_OUT_FILE&quot;可以获得如下所示的输出用来分析实时的 GPU 占用情况：....| 69% 72C P2 206W / 250W | 10538MiB / 11019MiB | 86% Default |1650966846.042205165| 69% 72C P2 193W / 250W | 10538MiB / 11019MiB | 86% Default |1650966846.324194099| 69% 72C P2 190W / 250W | 10538MiB / 11019MiB | 86% Default |1650966846.610179581....执行训练任务所用的命令如下所示：docker run --rm \\ --name &quot;$DOCKER_NAME&quot; \\ --gpus &quot;\\&quot;device=$GPU_ID\\&quot;&quot; \\ # ... docer run 的其他参数省略 tensorflow/tensorflow:1.11.0-gpu \\ bash -c &quot; \\ python2 run_classifier.py \\ -- ... 参数省略 \\ ; sleep 0.5&quot;由于该 docker run 命令添加了 --rm 选项，并且在执行训练任务后 sleep 0.5 ，因此，当训练任务结束后 0.5s，该 container 就会被删掉。利用这一特性，可以使用 docker exec 来监控 GPU，训练任务结束 0.5s 后，监控任务会被杀掉从而结束监控。命令如下所示：# $TMP_FILE 是用来防止 watch 命令的显示界面占用 shell 窗口docker exec -t $DOCKER_NAME bash -c &quot;watch -n 0.2 \\&quot;nvidia-smi | grep % &amp;gt;&amp;gt;$NVIDIA_OUT_FILE\\&quot;&quot; &amp;gt; $TMP_FILE为了能够在任务开始时及时开始监控 GPU，我的 shell script 中有如下命令。trainMain &amp;amp;while :; do sleep 0.2 # 失败后下次循环再次尝试，成功后break循环 res=$(./get_nvidia.sh -d &quot;$DOCKER_NAME&quot; -f &quot;$NVIDIA_FILE&quot; 2&amp;gt;&amp;amp;1 | grep &quot;Error&quot;) if [[ -z &quot;$res&quot; ]]; then break fidone其中 trainMain 函数主要功能是运行 docker run 以开启训练任务。get_nvidia.sh 中即为上述 docker exec 命令，由于 container 的建立需要时间，若在建立完成前运行 docker exec，将会报错：Error: No such container: ...（ ... 处为 $DOCKER_NAME 的值），因此需要每 0.2s 尝试一次，直到 docker exec 成功执行。测试对于所有测试，如下的超参数固定： max_seq_length = 128 learning_rate = 2e-5 num_train_epochs = 5对于可用的 24 个 BERT 模型，本次实验仅测试了 BERT-Tiny (2/128)、BERT-Mini (4/256)、BERT-Small (4/512)、BERT-Medium (8/512)、BERT-Base (12/768)。任务描述：CoLA 是 GLUE 中的一个单句子分类任务，语料来自语言理论的书籍和期刊，每个句子被标注为是否合乎语法的单词序列。本任务是一个二分类任务，标签共两个，分别是 0 和 1，其中 0 表示不合乎语法，1 表示合乎语法。样本个数：训练集 8,551 个，开发集 1,043 个，测试集 1,063 个。在相同的学习率与相同 max sequence length 下微调训练后，可以得出结论，对于不同的 BERT 模型，模型规模越大，其模型的估计准确度越高，但随之，每个 Epoch 所用时间越长，功耗也越大，GPU 利用率也越高。对于相同的 BERT 模型，增加 batch size，并不能给预测准确率带来提升，但其每个 epoch 所花费的时间明显减少，虽然 GPU 的功率也随之增加，但从整体来看，每个 epoch 所花费的能耗是降低的。附录：实验数据ModelBatch SizeEvaluated AccuracyEvaluated LossTrain LossTime of Per EpochAverage Power (Rated Power: 250W)Average Memory (All Memory: 11019MiB)Average UtilizationReal time GPU performanceTiny269.13%0.900.9053.11s89.68W10486.2MiB33.16%Tiny469.13%0.620.6223.33s103.02W10431.9MiB35.31%Tiny869.13%0.620.6215.17s95.64W10413.6MiB29.60%Tiny1669.13%0.610.615.73s115.74W10291.1MiB35.01%Tiny3269.13%0.620.623.21s117.05W10118.2MiB36.09%Tiny6469.13%0.620.622.53s126.77W10048.6MiB38.79%Mini270.57%1.141.14102.27s111.77W10509.9MiB36.02%Mini470.37%0.840.8451.18s118.30W10494.2MiB38.39%Mini870.18%0.630.6326.27s138.96W10459.0MiB42.70%Mini1669.22%0.620.6214.14s158.72W10389.6MiB50.77%Mini3270.76%0.610.6110.54s165.95W10383.2MiB54.42%Mini6469.51%0.620.628.92s174.75W10361.4MiB58.74%Small274.02%1.511.52112.29s147.67W10515.0MiB59.22%Small474.40%1.341.3456.64s182.98W10480.8MiB66.60%Small873.44%0.991.0034.76s203.46W10475.2MiB73.51%Small1674.21%0.730.7425.74s204.59W10462.6MiB74.33%Small3273.54%0.720.7320.50s203.58W10426.4MiB75.43%Small6473.73%0.700.7018.03s204.82W10436.3MiB77.36%Medium278.72%1.521.52176.69s153.54W10523.1MiB61.83%Medium478.62%1.301.3194.66s194.78W10512.7MiB69.43%Medium878.52%1.141.1560.66s204.15W10492.2MiB76.68%Medium1677.85%0.880.8947.73s205.18W10482.9MiB76.96%Medium3278.62%0.710.7138.97s206.95W10486.3MiB78.64%Medium6479.10%0.710.7234.70s212.36W10479.2MiB81.29%Base283.13%1.521.53324.06s190.54W10528.7MiB83.31%Base482.84%1.261.27196.86s212.73W10525.8MiB86.83%Base881.88%1.151.16140.55s213.59W10514.1MiB86.66%Base1683.22%0.890.90113.88s219.03W10514.8MiB87.67%Base3281.02%0.810.8298.39s223.67W10511.9MiB88.19%" }, { "title": "From C To C++", "url": "/posts/2022/04/From-C-To-C++/", "categories": "Learning, C++", "tags": "C++", "date": "2022-04-24 00:00:00 +0800", "snippet": "C++ 类与对象C++ 类 (Class) 可以看做是 C 中结构体 (Struct) 升级版。Class 的成员不仅仅可以是变量还可以是函数，类的成员变量称为“属性 (Property)”，成员函数称为“方法(Method)”。通过类定义出来的变量叫做“对象(Object)”，创建对象的过程叫做类的实例化，因此也称对象是类的一个“实例 (Instance)”。C++ 的编译与运行C 语言源文件后缀都是 .c，头文件后缀都是 .h；但对于 C++，不同编译器支持的后缀不太一样，常用的 C++ 头文件后缀有 .h、.hpp、.hxx，常用的 C++ 源文件的后缀有 .cpp、.cc、.cxx、.C、.c++。在 C 语言中，我们可以使用 gcc 命令来编译和链接 C 程序。编译 C++ 时，gcc 命令也可以使用，不过要增加 -lstdc++ 选项；不过 GCC 中还有一个专门用来编译 C++ 程序的 g++ 命令，也可以用它来编译 C++。C++ 命名空间为了解决合作开发时的命名冲突问题，C++ 引入了命名空间 (Namespace)，定义一个命名空间的语法格式为：namespace name { // #define // typedef // variables // functions // classes // ...}:: 为 C++ 中的新符号，称为”域解析操作符 (scope resolution operator)“，要使用命名空间中定义的变量函数等，可以用 name::variable， name::function 等来使用。除了直接使用域解析操作符，还可以使用 using 关键字声明：using name::variable;// 就可以直接使用 variablevariable = 1;using 关键字也可以直接声明整个命名空间：using name; // 后续作用范围内的代码可以直接使用 name 中定义的 variables，functions，...// 若未具体指定命名空间的变量发生命名冲突，默认采用命名空间 name 中的变量std 是 C++ 标准库类型对象的命名空间。 早期 C++ 不完善的时候，还不支持命名空间，这时 C++ 还在使用 C 的库，stdio.h、stdlib.h、string.h 等头文件仍然有效，C++ 也开发了一些新的库，添加了如 iostream.h、fstream.h、complex.h 的头文件。 后来 C++ 引入命名空间的概念，将库、类、函数、宏等都统一纳入一个命名空间，即 std，但为了兼容早期的老式 C++，故保留原来的 .h 头文件和库，然后把原来的库复制一份，并稍加修改后将库、类、函数、宏等纳入命名空间 std。为了避免头文件重名，新版的 C++ 库的头文件，对于 C++ 语言新增的头文件，其命名去掉了 .h 后缀，即 iostream.h 变为了 iostream；而原来的 C 语言头文件，去掉后缀 .h 并添加前缀 c，即 stdio.h 变为了 cstdio。 虽然早期的 C++ 头文件（如 iostream.h）与 C 头文件（如 stdio.h）仍被支持，但其内容却不在命名空间 std 中。因此，对原来的头文件，即使按 C++ 方式来引入（如 #include &amp;lt;cstdio&amp;gt;），其符号也既可以位于命名空间 std 中，可以位于全局范围内。C++ 输入输出C 语言中，通常使用 scanf 和 printf 进行输入输出，而在 C++ 中，这两个函数仍可以使用，但 C++ 添加一套新的，更容易使用的输入输出库。即使用 &amp;lt;iostream&amp;gt; 中定义的输入输出对象 cin、 cout、cerr。如下是一个示例，具体使用于后续章节。int num;std::cin &amp;gt;&amp;gt; num;std::cout &amp;lt;&amp;lt; &quot;Hello World! Input is:&quot; &amp;lt;&amp;lt; num &amp;lt;&amp;lt; std::endl;C++ 变量定义位置C 语言中，C89 规定，所有局部变量必须定义在函数开头，C99 标准取消了这条限制。C++ 标准取消了这个限制，变量只要在使用之前定义好即可。C++ 布尔类型在 C 语言中表示真假： 0 为假，非 0 为真。而 C++ 中新增 bool 类型，一般占 1 字节长度，值为 true（真） 和 false（假）。C++ 常量 (Constant)在 C 语言中，const 用来限制一个变量，表示这个变量不能修改。在 C++ 中，const 的含义并没有改变，但是其有一些细节上的不同。 C 语言中，const 变量的读取需要访问内存；而在 C++ 中，对 const 变量的取值会在编译阶段完成值替换，有点类似于 #define，但是 #define 的值替换是在预处理阶段。 C 语言中，const 全局变量的可见范围是整个程序，在其他文件中使用 extern 声明即可使用；但在 C++ 中 const 全局变量的可见范围仅限于当前文件，在其他文件中不可见，因此可以定义在头文件中，多次引入也不会出错。C++ 动态内存分配管理C 语言中，动态内存管理用 malloc() 和 free() 函数。C++ 中，这两个函数仍可以使用，但新增两个关键字，new 和 delete。int *p = new int;int *arr = new int[24];delete p;delete[] arr;C++ 中，建议使用 new 和 delete 来管理内存分配，其最明显的特性是可以自动调用构造函数和析构函数。C++ inline 函数为了消除函数调用的时空开销，C++ 提供了一种高效的方法 —— 内联函数（Inline Function），其在编译时会将函数调用用函数体替换掉。（inline 声明只是程序员对编译器提出的建议，怎样做由编译器自己决定。）inline int func(int a, int b) { // functions body}由于内联函数会在编译期间进行替换，所以我们可以将容易踩坑的宏 (#define) 替换为内联函数。如：// 宏 SQ 可以替换为内联函数 sq#define SQ(y) ((y) * (y))inline int sq(int y) { return y * y; }inline 关键字要在函数定义处添加，在函数声明处的 inline 关键字会被编译器忽略。 更严格来说，内联函数不应该有声明。在多文件编程中，通常会把函数定义放在源文件，函数声明放在头文件，但这种做法不适用于内联函数，将内联函数的声明和定义分放在不同文件会出错。这是因为程序会先在编译期间用对内联函数进行替换，替换后，内联函数定义将不存在，其后进行链接时，有内联函数声明的文件将找不到内联函数定义，从而链接错误。C++ 函数重载在 C 语言中，要实现功能相近但参数列表不同的函数，只能分别设计出多个不同函数名的函数。但在 C++ 中，可以实现函数重载 (Function Overloading)，它允许多个函数拥有相同的名字，只要他们的参数列表不同就可以（参数列表不同包含参数类型、数量或顺序的不同）。注意仅仅是返回值的不同不能作为重载的依据。这是因为 C++ 编译时会根据参数列表对函数进行重命名，如 bool func(int a, int b) 会被重命名为 _func_int_int，而 bool func(float a, float b) 会被重命名为 _func_float_float（不同编译器有不同的重命名方式，仅做举例说明）。函数重载匹配优先级： 精确匹配 直接匹配 从数组名到数组指针，从函数名到函数指针，从非 const 到 const 的类型转换 类型提升后匹配（不会降低数据精度） 整型：bool、char、short 转换为 int，char16_t、char32_t、wchar_t 转换为 int、long、long long。 浮点：float 转换为 double 自动类型转换后匹配（除类型提升外的可行的类型转换，精度可能会降低）如果在同一个优先级中，找到多个合适的重载函数，编译器不知道如何抉择，就会发生编译错误。若函数有多个参数，而有参数对不同函数重载的优先级胜出结果不一致，编译器也会不知如何抉择，从而发生二义性错误。C++ 与 C 混合编程C++ 支持函数重载，会在编译阶段对函数名进行重命名；而 C 不支持函数重载，所以并不会在编译阶段对函数名进行太大的修改。由于 C 和 C++ 对函数名的处理不同，若要进行 C 和 C++ 的混合编程，比如将 test1.c 和 test2.cpp 编译链接，将会在链接阶段无法找到函数的具体实现而报错。C++ 中提供了相应的解决方案，即借助 extern &quot;C&quot;。extern &quot;C&quot; 可以用来修饰一句/段 C++ 代码，其作用是让编译器以 C 的方式来处理修饰 C++ 代码。对于 C 和 C++ 混合编程的问题，可以在头文件中使用如下格式：#ifdef _cplusplusextern &quot;C&quot; {#endif/* 需要修饰的声明 */void func(int a);#ifdef _cplusplus}#endif" } ]
